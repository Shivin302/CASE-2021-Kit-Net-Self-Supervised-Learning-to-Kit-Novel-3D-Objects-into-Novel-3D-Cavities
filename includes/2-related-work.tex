\section{Related Work}
\label{sec:related-work}
% Classical Methods
%Reorienting objects is an important subtask in a variety of domains, such as manufacturing, packing, and assembly.
There has been significant prior work on reorienting objects using geometric algorithms. \citet{goldberg1993orienting} proposes a geometric algorithm that orients polygonal parts with known geometry without requiring sensors. \citet{akella-orienting-uncertainty} extend the work of Goldberg with sensor-based and sensor-less algorithms for orienting objects with known geometry and shape variation. \citet{kumbla2018enabling} propose a method for estimating object pose via computer vision and then reorient the object using active probing. \citet{grasp-gaits} optimize robot finger motions to reorient a known convex object while maintaining grasp stability. In contrast to the above works, which require prior knowledge of object geometry, Kit-Net can reorient objects without 3D object models.
% Traditional Pose Estimation
% \SD{Copied from CASE: Another approach to reorienting objects explored by prior work uses statistical methods for pose estimation. The goal in this approach is to estimate the 6-DOF (translation + rotation) pose of an object with known geometry subject to uncertainty in sensing and occlusions. If 6-DOF poses can reliably be estimated, then re-orientation plans can be computed using the difference between the pose of the object in its initial orientation and its goal orientation. % and simply computing the required rotation. 
% \citet{hodan2018bop} provides eight datasets to train and test pose estimation algorithms and a consistent benchmark that works well for evaluating various methods on symmetric and partially occluded objects. \citet{prokudin2018deep, kingma2013auto} introduce a variational-auto-encoder-based probabilistic model for pose estimation. \citet{xiang2017posecnn} use semantic labeling and bounding-box prediction as surrogate tasks to perform pose estimation via quaternion regression with a new symmetry-invariant loss function.  \citet{Li2019DeepIMDI} builds on prior work by using PoseCNN~\citet{xiang2017posecnn} to provide an initial pose estimate and then iteratively refines it by matching the image rendered based on the pose estimate and the observed image of the object. 
% \citet{Do2018Deep6DPoseR6} use Mask-RCNN to perform instance segmentation and then finds a Lie algebra representation of the 6D pose of each object in a given image.
% \citet{tian2020robust} learn to predict the rotation of symmetric objects by learning directly from their RGB-D features, improve upon Shape-Match Loss of \citet{xiang2017posecnn}, and include an uncertainty on the rotation prediction. 
% \citet{peretroukhin2020smooth} proposes a novel representation of $SO(3)$ which incorporates the belief over the predicted rotation, making the learned model robust to unseen objects and scenes. 
% \citet{hagelskjaer2019using} uses spatial reasoning and workcell constraints to accurately estimate poses. \citet{deng2019self} improve upon object segmentation and pose estimation with a self-supervised method of collecting training data from real images using an RGBD camera mounted onto the hand of a robot manipulator.
% In contrast to these works, we propose a method that does not require prior knowledge of object geometry and can generalize to objects outside of those seen during training. }

% % Pose Estimation of unseen objects
% \SD{Copied from CASE: Some recent work explores pose estimation for objects unseen during training. \citet{corona2018pose} predict the pose of objects unseen at training time, but require a 3D model to adjust for ambiguities due to symmetry. \citet{Xiao2019PoseFS} trains a pose-estimation network that is conditioned on a test image and 3D object model, making it possible to predict the pose of arbitrary objects in varied visual environments if 3D models of the objects are available. These works can generalize to unseen objects, but still require 3D object models. \citet{park2019latentfusion} relax this assumption by estimating a 3D geometric model by learning a 3D object representation that enforces consistency across multiple views. Then, this estimated 3D object model can be rendered as a depth image of the object in a desired pose. This enables generalization to objects with unknown geometry, but requires that multiple views of each object are available at test time. 
% \citet{wang20196-pack} extract 3D keypoints from RGBD images of unseen objects for real-time pose tracking, but require that test objects be relatively similar to those seen in training.}

% Delta pose
\citet{delta-pose-est}, \citet{latent-3d-keypoints}, \citet{Wen2020se3TrackNetD6}, and \citet{CASE_Orienting} use data-driven approaches to estimate the relative pose difference between images of an object in different configurations.  
\citet{delta-pose-est} use a Siamese network to estimate the relative pose between two cameras given an RGB image from each camera. \citet{latent-3d-keypoints} propose KeypointNet, a deep learning approach that learns 3D keypoints by estimating the relative pose between two different RGB images of an object of unknown geometry, but known category. 
\citet{Wen2020se3TrackNetD6} considers an object tracking task by estimating a change in pose between an RGBD image of the object at the current timestep and a rendering of the object at the previous timestep, but require a known 3D object model. We use the network architecture from \citet{Wen2020se3TrackNetD6} to train Kit-Net, and extend the self-supervised training method and controller from \citet{CASE_Orienting} to kit novel objects into previously unseen cavities. We find that by extending~\citet{CASE_Orienting} to be more robust to object translations and using a suction gripper to reduce occlusions, Kit-Net is able to learn more accurate reorientation controllers.

There has also been significant interest in leveraging ideas in pose estimation for core tasks in industrial automation.
\citet{Litvak2019LearningPE} leverage CAD models and assemble gear like mechanisms using depth images taken from a camera on a robotic arm's end effector. \citet{Stevic2020LearningTA} estimate a goal object's pose to perform a shape assembly task involving inserting objects which conform to a specific shape template into a prismatic cavity. \citet{Zachares2021InterpretingCI} combines vision and tactile
sensorimotor traces for an object fitting task involving known holes and object types.
\citet{Huang2020Generative3P} consider the problem of assembling a 3D shape composed of several different parts. This method assumes known part geometry and develops an algorithm to generate the 6-DOF poses that will rearrange the parts to assemble the desired 3D shape. In contrast to the above work, we focus on the problem of designing a controller which can reorient and place a novel object within a previously unseen cavity for industrial kitting tasks. 

Object kitting has also seen recent interest from the robotics community. \citet{Zakka2020Form2FitLS} introduce Form2Fit, an algorithm which learns $SE(2)$ transforms to perform pick-and-place for kitting planar objects. In contrast, we consider 6DOF transforms of 3D objects.
\citet{zeng2020transporter} propose a network for selecting suction grasps and grasp-conditioned placement, which can generalize to multiple robotic manipulation tasks, including pick-and-place for novel flat objects. \citeauthor{zeng2020transporter} focuses on $SE(2)$ rotations and translations for pick-and-place tasks involving novel flat, 2D extruded objects. \citeauthor{zeng2020transporter} also presents an algorithm for $SE(3)$ pick-and-place tasks, but only evaluate the algorithm on 2D extruded objects. In contrast, we use Kit-Net to kit novel 3D objects with a wide range of complex geometries.